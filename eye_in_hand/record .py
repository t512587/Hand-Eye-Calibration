import pyrealsense2 as rs
import numpy as np
import cv2
import datetime
import json
import os
from pymycobot.elephantrobot import ElephantRobot

# === æ£‹ç›¤æ ¼è¨­å®š ===
CHESSBOARD_SIZE = (9, 6)  # å…§è§’é»æ•¸é‡ (åˆ—, è¡Œ)
SQUARE_SIZE = 0.025  # æ¯å€‹æ–¹æ ¼çš„å¯¦éš›å¤§å°ï¼Œå–®ä½: å…¬å°º (25mm)

# === ç”Ÿæˆæ£‹ç›¤æ ¼ 3D ç‰©ä»¶é» ===
def create_chessboard_points():
    """
    ç”Ÿæˆæ£‹ç›¤æ ¼çš„ 3D ä¸–ç•Œåº§æ¨™é»
    åŸé»åœ¨æ£‹ç›¤æ ¼å·¦ä¸Šè§’ï¼ŒZ=0 å¹³é¢
    """
    objp = np.zeros((CHESSBOARD_SIZE[0] * CHESSBOARD_SIZE[1], 3), np.float32)
    objp[:, :2] = np.mgrid[0:CHESSBOARD_SIZE[0], 0:CHESSBOARD_SIZE[1]].T.reshape(-1, 2)
    objp *= SQUARE_SIZE
    return objp

# === åˆå§‹åŒ–é€£ç·š ===
elephant_client = ElephantRobot("192.168.50.123", 5001)
elephant_client.start_client()
print("ElephantRobotç›®å‰åº§æ¨™ï¼š", elephant_client.get_coords())

# === åˆå§‹åŒ– RealSense ç›¸æ©Ÿ ===
pipeline = rs.pipeline()
config = rs.config()
config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)
pipeline.start(config)

# === å–å¾—å…§åƒ ===
profile = pipeline.get_active_profile()
video_stream_profile = profile.get_stream(rs.stream.color)
intr = video_stream_profile.as_video_stream_profile().get_intrinsics()

camera_matrix = np.array([
    [intr.fx, 0, intr.ppx],
    [0, intr.fy, intr.ppy],
    [0, 0, 1]
])
dist_coeffs = np.array(intr.coeffs[:5]).reshape(5, 1) if len(intr.coeffs) >= 5 else np.zeros((5, 1))

print("\n=== ç›¸æ©Ÿå…§åƒ ===")
print(f"ç„¦è·: fx={intr.fx:.3f}, fy={intr.fy:.3f}")
print(f"ä¸»é»: cx={intr.ppx:.3f}, cy={intr.ppy:.3f}")
print(f"ç•¸è®Šä¿‚æ•¸: {intr.coeffs}")

# === æ£‹ç›¤æ ¼ 3D é» ===
objp = create_chessboard_points()

# === è³‡æ–™å„²å­˜ ===
output_data = []
save_dir = "handeye_records"
os.makedirs(save_dir, exist_ok=True)

print(f"\n=== æ‰‹çœ¼æ¨™å®šè³‡æ–™è¨˜éŒ„ç³»çµ± (æ£‹ç›¤æ ¼ {CHESSBOARD_SIZE[0]}x{CHESSBOARD_SIZE[1]}) ===")
print(f"æ–¹æ ¼å¤§å°: {SQUARE_SIZE * 1000:.1f} mm")
print("s - è¨˜éŒ„æ£‹ç›¤æ ¼ + æ©Ÿæ¢°æ‰‹åˆå§‹å§¿æ…‹")
print("m - è¨˜éŒ„è©²é»ç§»å‹•å¾Œçš„å§¿æ…‹")
print("v - æŸ¥çœ‹å·²è¨˜éŒ„è³‡æ–™")
print("r - é‡ç½®è³‡æ–™")
print("q - é›¢é–‹ä¸¦å„²å­˜")
print("=" * 50)

# è§’é»å„ªåŒ–åƒæ•¸
criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)

try:
    current_index = 0
    last_rvec = None
    last_tvec = None
    chessboard_found = False

    while True:
        frames = pipeline.wait_for_frames()
        color_frame = frames.get_color_frame()
        if not color_frame:
            continue

        color_image = np.asanyarray(color_frame.get_data())
        gray = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)

        # æª¢æ¸¬æ£‹ç›¤æ ¼è§’é»
        ret, corners = cv2.findChessboardCorners(
            gray, CHESSBOARD_SIZE,
            cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_NORMALIZE_IMAGE + cv2.CALIB_CB_FAST_CHECK
        )

        chessboard_found = ret

        if ret:
            # å„ªåŒ–è§’é»ä½ç½®
            corners_refined = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)

            # ç¹ªè£½æ£‹ç›¤æ ¼è§’é»
            cv2.drawChessboardCorners(color_image, CHESSBOARD_SIZE, corners_refined, ret)

            # ä½¿ç”¨ solvePnP è¨ˆç®—å§¿æ…‹
            success, rvec, tvec = cv2.solvePnP(
                objp, corners_refined, camera_matrix, dist_coeffs,
                flags=cv2.SOLVEPNP_ITERATIVE
            )

            if success:
                last_rvec = rvec
                last_tvec = tvec

                # ç¹ªè£½åº§æ¨™è»¸
                cv2.drawFrameAxes(color_image, camera_matrix, dist_coeffs, rvec, tvec, SQUARE_SIZE * 3)

                # é¡¯ç¤ºä½ç½®è³‡è¨Š
                tvec_mm = tvec.flatten() * 1000
                cv2.putText(color_image, f"Pos: ({tvec_mm[0]:.0f}, {tvec_mm[1]:.0f}, {tvec_mm[2]:.0f}) mm",
                            (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                
                # é¡¯ç¤ºæ£‹ç›¤æ ¼æª¢æ¸¬æˆåŠŸ
                cv2.putText(color_image, "Chessboard DETECTED", (10, 60),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        else:
            cv2.putText(color_image, "Chessboard NOT found", (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)

        # é¡¯ç¤ºå·²è¨˜éŒ„æ•¸é‡
        cv2.putText(color_image, f"Recorded: {len(output_data)} poses", (10, color_image.shape[0] - 20),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)

        cv2.imshow("Hand-Eye Calibration (Chessboard)", color_image)
        key = cv2.waitKey(1) & 0xFF

        if key == ord('q'):
            break

        elif key == ord('s') and chessboard_found and last_rvec is not None:
            # è¨˜éŒ„æ£‹ç›¤æ ¼å§¿æ…‹å’Œæ©Ÿå™¨äººå§¿æ…‹
            rvec_list = last_rvec.flatten().tolist()
            tvec_mm = (last_tvec.flatten() * 1000).tolist()  # è½‰æ›ç‚º mm
            robot_pose = elephant_client.get_coords()

            entry = {
                "marker_id": 0,  # æ£‹ç›¤æ ¼çµ±ä¸€ä½¿ç”¨ ID 0
                "aruco_tvec": tvec_mm,  # ä¿æŒç›¸å®¹æ€§ï¼Œä½¿ç”¨ç›¸åŒçš„æ¬„ä½åç¨±
                "aruco_rvec": rvec_list,
                "robot_pose_at_detect": robot_pose,
                "robot_pose_after_move": None,
                "type": "chessboard",
                "chessboard_size": list(CHESSBOARD_SIZE),
                "square_size_mm": SQUARE_SIZE * 1000
            }

            output_data.append(entry)
            current_index = len(output_data) - 1

            print(f"\nâœ… å·²è¨˜éŒ„ç¬¬ {current_index + 1} ç­†")
            print(f"æ£‹ç›¤æ ¼ä½ç½® (mm): {tvec_mm}")
            print(f"æ—‹è½‰å‘é‡: {rvec_list}")
            print(f"æ‰‹è‡‚å§¿æ…‹: {robot_pose}")

        elif key == ord('m') and output_data and output_data[current_index]["robot_pose_after_move"] is None:
            moved_pose = elephant_client.get_coords()
            output_data[current_index]["robot_pose_after_move"] = moved_pose
            print(f"ğŸ” å·²è£œä¸Šç§»å‹•å¾Œæ‰‹è‡‚å§¿æ…‹ï¼š{moved_pose}")

        elif key == ord('v'):
            print(f"\nğŸ“‹ å·²è¨˜éŒ„ {len(output_data)} ç­†è³‡æ–™ï¼š")
            for i, d in enumerate(output_data):
                moved = "âœ…" if d["robot_pose_after_move"] else "â³"
                print(f"  ç¬¬ {i+1} ç­† {moved}")

        elif key == ord('r'):
            output_data = []
            print("ğŸ”„ å·²æ¸…ç©ºæ‰€æœ‰è¨˜éŒ„")

finally:
    pipeline.stop()
    cv2.destroyAllWindows()

    if output_data:
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = os.path.join(save_dir, f"handeye_chessboard_{timestamp}.json")
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(output_data, f, indent=2)
        print(f"\nğŸ’¾ å·²å„²å­˜ {len(output_data)} ç­†è³‡æ–™è‡³ {filename}")
    print("ğŸ“Œ ç¨‹å¼çµæŸ")